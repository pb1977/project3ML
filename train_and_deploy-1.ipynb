{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Project 3</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Run this is Sagemaker Notebook</h3>\n",
    "<h3>Install and import</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting smdebug\n",
      "  Downloading smdebug-1.0.12-py2.py3-none-any.whl (270 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.1/270.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from smdebug) (4.23.4)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from smdebug) (1.24.4)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from smdebug) (21.3)\n",
      "Requirement already satisfied: boto3>=1.10.32 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from smdebug) (1.28.57)\n",
      "Collecting pyinstrument==3.4.2 (from smdebug)\n",
      "  Downloading pyinstrument-3.4.2-py2.py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.3/83.3 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyinstrument-cext>=0.2.2 (from pyinstrument==3.4.2->smdebug)\n",
      "  Downloading pyinstrument_cext-0.2.4.tar.gz (4.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: botocore<1.32.0,>=1.31.57 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3>=1.10.32->smdebug) (1.31.57)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3>=1.10.32->smdebug) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.8.0,>=0.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3>=1.10.32->smdebug) (0.7.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging->smdebug) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore<1.32.0,>=1.31.57->boto3>=1.10.32->smdebug) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore<1.32.0,>=1.31.57->boto3>=1.10.32->smdebug) (1.26.14)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.32.0,>=1.31.57->boto3>=1.10.32->smdebug) (1.16.0)\n",
      "Building wheels for collected packages: pyinstrument-cext\n",
      "  Building wheel for pyinstrument-cext (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyinstrument-cext: filename=pyinstrument_cext-0.2.4-cp310-cp310-linux_x86_64.whl size=6295 sha256=da362263433d9415911436ad39b81046792d97bc38dcca4861c22415cc6c2474\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/0f/8b/7a/5f7fd1dd6d3cbb3d350d4c832c5e2f962687749f6d67d573a6\n",
      "Successfully built pyinstrument-cext\n",
      "Installing collected packages: pyinstrument-cext, pyinstrument, smdebug\n",
      "Successfully installed pyinstrument-3.4.2 pyinstrument-cext-0.2.4 smdebug-1.0.12\n",
      "Requirement already satisfied: smdebug in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.0.12)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from smdebug) (4.23.4)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from smdebug) (1.24.4)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from smdebug) (21.3)\n",
      "Requirement already satisfied: boto3>=1.10.32 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from smdebug) (1.28.57)\n",
      "Requirement already satisfied: pyinstrument==3.4.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from smdebug) (3.4.2)\n",
      "Requirement already satisfied: pyinstrument-cext>=0.2.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pyinstrument==3.4.2->smdebug) (0.2.4)\n",
      "Requirement already satisfied: botocore<1.32.0,>=1.31.57 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3>=1.10.32->smdebug) (1.31.57)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3>=1.10.32->smdebug) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.8.0,>=0.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3>=1.10.32->smdebug) (0.7.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging->smdebug) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore<1.32.0,>=1.31.57->boto3>=1.10.32->smdebug) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore<1.32.0,>=1.31.57->boto3>=1.10.32->smdebug) (1.26.14)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.32.0,>=1.31.57->boto3>=1.10.32->smdebug) (1.16.0)\n",
      "Collecting protobuf==3.20.*\n",
      "  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.23.4\n",
      "    Uninstalling protobuf-4.23.4:\n",
      "      Successfully uninstalled protobuf-4.23.4\n",
      "Successfully installed protobuf-3.20.3\n"
     ]
    }
   ],
   "source": [
    "!pip install smdebug;\n",
    "! pip install -U smdebug;\n",
    "! pip install protobuf==3.20.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'us-east-1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.tuner import CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.debugger import Rule, DebuggerHookConfig, TensorBoardOutputConfig, CollectionConfig, ProfilerRule, rule_configs, ProfilerConfig, FrameworkProfile\n",
    "from sagemaker.analytics import HyperparameterTuningJobAnalytics\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "my_session = boto3.session.Session()\n",
    "region = my_session.region_name\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"sagemaker/project3\"\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Retrieve the data and copy it to S3</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!wget https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip\n",
    "!unzip dogImages.zip\n",
    "#!aws s3 cp dogImages s3://udacitysolution/ --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload files to s3\n",
    "inputs = sagemaker_session.upload_data(path=\"dogImages\", bucket=bucket, key_prefix=prefix)\n",
    "print(\"input spec (in this case, just an S3 path): {}\".format(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "number of classes for test is 133\n",
      "number of classes for train is 133\n",
      "number of classes for valid is 133\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "bucket = \"sagemaker-us-east-1-053987932055\" \n",
    "prefix = \"sagemaker/project3\"\n",
    "s3 = boto3.client('s3')\n",
    "testlist = []\n",
    "trainlist = []\n",
    "validlist = []\n",
    "r = [(testlist,'test'), (trainlist,'train'), (validlist,'valid')]\n",
    "\n",
    "for i in r:\n",
    "   \n",
    "    result = s3.list_objects_v2(Bucket=bucket, Prefix='sagemaker/project3/{}/'.format(i[1]),    Delimiter='/')\n",
    "    for obj in result.get('CommonPrefixes'):\n",
    "\n",
    "        i[0].append(obj.get('Prefix').split('.')[1].split('/')[0])                            \n",
    "    print('number of classes for {} is {}'.format(i[1],len(i[0])))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Declare your HP ranges, metrics etc.\n",
    "hyperparameter_ranges = {\n",
    "    \"learning-rate\": ContinuousParameter(0.001, 0.1),\n",
    "    \"batch-size\": CategoricalParameter([32, 64, 128, 256]),\n",
    "    \"epochs\": CategoricalParameter([3, 5, 10, 20])\n",
    "}\n",
    "\n",
    "objective_metric_name = \"average test loss\"\n",
    "objective_type = \"Minimize\"\n",
    "metric_definitions = [{\"Name\": \"average test loss\", \"Regex\": \"Test set: Average loss: ([0-9\\\\.]+)\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "# Create estimators for the HPs\n",
    "\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"hpo1.py\",\n",
    "    role=role,\n",
    "    py_version='py36',\n",
    "    framework_version=\"1.8\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.p3.2xlarge\" #\"ml.g4dn.2xlarge\"  # GPU\n",
    ")\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions,\n",
    "    max_jobs=2,\n",
    "    max_parallel_jobs=1,\n",
    "    objective_type=objective_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_path= \"s3://{}/{}/{}/\".format(bucket, prefix, 'train')\n",
    "valid_path= \"s3://{}/{}/{}/\".format(bucket, prefix, 'valid')\n",
    "test_path= \"s3://{}/{}/{}/\".format(bucket, prefix, 'test')\n",
    "\n",
    "s3_output_dir = \"s3://{}/{}/\".format(bucket, prefix)\n",
    "s3_model_dir = \"s3://{}/{}/\".format(bucket, \"project_image_classification/model\")\n",
    "\n",
    "os.environ['SM_CHANNEL_TRAIN']=train_path\n",
    "os.environ['SM_CHANNEL_VAL']=valid_path\n",
    "os.environ['SM_CHANNEL_TEST']=test_path\n",
    "os.environ['SM_MODEL_DIR']=s3_model_dir\n",
    "os.environ['SM_OUTPUT_DATA_DIR']=s3_output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n",
      ".....................................................................................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "tuner.fit({\"train\": train_path, \"val\": valid_path, \"test\": test_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "Number of training jobs with valid objective: 2\n",
      "{'lowest': 0.033799998462200165, 'highest': 0.050200000405311584}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch-size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>learning-rate</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"32\"</td>\n",
       "      <td>\"3\"</td>\n",
       "      <td>0.004563</td>\n",
       "      <td>pytorch-training-231016-1612-001-e090c177</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>2023-10-16 16:15:14+00:00</td>\n",
       "      <td>2023-10-16 16:26:16+00:00</td>\n",
       "      <td>662.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"128\"</td>\n",
       "      <td>\"5\"</td>\n",
       "      <td>0.088688</td>\n",
       "      <td>pytorch-training-231016-1612-002-81a9fffb</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.0502</td>\n",
       "      <td>2023-10-16 16:26:50+00:00</td>\n",
       "      <td>2023-10-16 16:35:34+00:00</td>\n",
       "      <td>524.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  batch-size epochs  learning-rate                            TrainingJobName  \\\n",
       "1       \"32\"    \"3\"       0.004563  pytorch-training-231016-1612-001-e090c177   \n",
       "0      \"128\"    \"5\"       0.088688  pytorch-training-231016-1612-002-81a9fffb   \n",
       "\n",
       "  TrainingJobStatus  FinalObjectiveValue         TrainingStartTime  \\\n",
       "1         Completed               0.0338 2023-10-16 16:15:14+00:00   \n",
       "0         Completed               0.0502 2023-10-16 16:26:50+00:00   \n",
       "\n",
       "            TrainingEndTime  TrainingElapsedTimeSeconds  \n",
       "1 2023-10-16 16:26:16+00:00                       662.0  \n",
       "0 2023-10-16 16:35:34+00:00                       524.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hpytuner = sagemaker.HyperparameterTuningJobAnalytics('pytorch-training-231016-1612')\n",
    "\n",
    "full_df = hpytuner.dataframe()\n",
    "\n",
    "if len(full_df) > 0:\n",
    "    df = full_df[full_df[\"FinalObjectiveValue\"] > -float(\"inf\")]\n",
    "    if len(df) > 0:\n",
    "        df = df.sort_values(\"FinalObjectiveValue\")\n",
    "        print(\"Number of training jobs with valid objective: %d\" % len(df))\n",
    "        print({\"lowest\": min(df[\"FinalObjectiveValue\"]), \"highest\": max(df[\"FinalObjectiveValue\"])})\n",
    "        pd.set_option(\"display.max_colwidth\", None)  # Don't truncate TrainingJobName\n",
    "    else:\n",
    "        print(\"No training jobs have reported valid results yet.\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "\n",
      "2023-10-16 16:26:49 Starting - Preparing the instances for training\n",
      "2023-10-16 16:26:49 Downloading - Downloading input data\n",
      "2023-10-16 16:26:49 Training - Training image download completed. Training in progress.\n",
      "2023-10-16 16:26:49 Uploading - Uploading generated training model\n",
      "2023-10-16 16:26:49 Completed - Resource reused by training job: pytorch-training-231016-1612-002-81a9fffb\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "my_training_job_name = 'pytorch-training-231016-1612-001-e090c177'\n",
    "tuner = PyTorch.attach(my_training_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_tuning_objective_metric': '\"average test loss\"',\n",
       " 'batch-size': '\"32\"',\n",
       " 'epochs': '\"3\"',\n",
       " 'learning-rate': '0.004563047309634722',\n",
       " 'sagemaker_container_log_level': '20',\n",
       " 'sagemaker_estimator_class_name': '\"PyTorch\"',\n",
       " 'sagemaker_estimator_module': '\"sagemaker.pytorch.estimator\"',\n",
       " 'sagemaker_job_name': '\"pytorch-training-2023-10-16-16-12-03-956\"',\n",
       " 'sagemaker_program': '\"hpo1.py\"',\n",
       " 'sagemaker_region': '\"us-east-1\"',\n",
       " 'sagemaker_submit_directory': '\"s3://sagemaker-us-east-1-053987932055/pytorch-training-2023-10-16-16-12-03-956/source/sourcedir.tar.gz\"'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch-size': '32', 'learning-rate': '0.004563047309634722', 'epochs': '3'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "hyperparameters = tuner.hyperparameters()\n",
    "\n",
    "hyperparameters = {\"batch-size\": tuner.hyperparameters()['batch-size'].replace('\"','' ), \\\n",
    "                   \"learning-rate\": tuner.hyperparameters()['learning-rate'],\n",
    "                    \"epochs\" : tuner.hyperparameters()['epochs'].replace('\"', '')}\n",
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.deprecations:Framework profiling will be deprecated from tensorflow 2.12 and pytorch 2.0 in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sagemaker.debugger import (\n",
    "    Rule,\n",
    "    DebuggerHookConfig,\n",
    "    CollectionConfig,\n",
    "    rule_configs,\n",
    "    ProfilerRule\n",
    ")\n",
    "class_imbalance_rule = Rule.sagemaker(base_config=rule_configs.class_imbalance(),\n",
    "                                     rule_parameters={\"labels_regex\": \"CrossEntropyLoss_input_1\",\n",
    "                                                      \"predictions_regex\": \"CrossEntropyLoss_input_0\",\n",
    "                                                      \"samples\":\"3000\",\n",
    "                                                      \"argmax\":\"True\",\n",
    "                                                     })\n",
    "\n",
    "dead_relu_rule = Rule.sagemaker(base_config=rule_configs.dead_relu(),\n",
    "                                rule_parameters={\"tensor_regex\": \".*^(?!gradient)(.*relu_output)\"})\n",
    "\n",
    "\n",
    "loss_not_decreasing_rule = Rule.sagemaker(base_config=rule_configs.loss_not_decreasing(),\n",
    "                             rule_parameters={\"tensor_regex\": \"CrossEntropyLoss_CrossEntropyLoss_output_0\",\n",
    "                                              \"num_steps\": \"500\",\n",
    "                                              \"mode\": \"TRAIN\"})\n",
    "\n",
    "from sagemaker.debugger import DebuggerHookConfig, CollectionConfig\n",
    "\n",
    "debugger_hook_config = DebuggerHookConfig(\n",
    "      collection_configs=[ \n",
    "          CollectionConfig(\n",
    "                name=\"custom_collection\",\n",
    "                parameters={ \"include_regex\": \".*ReLU_output|.*ResNet_input|.*image|.*CrossEntropyLoss\",\n",
    "                             \"train.save_interval\": \"100\",\n",
    "                             \"eval.save_interval\": \"25\" })])\n",
    "\n",
    "\n",
    "from sagemaker.debugger import ProfilerConfig, FrameworkProfile\n",
    "\n",
    "profiler_config = ProfilerConfig(\n",
    "    system_monitor_interval_millis=500, framework_profile_params=FrameworkProfile(num_steps=10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2023-10-17-16-35-23-026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-17 16:35:23 Starting - Starting the training job...ClassImbalance: InProgress\n",
      "DeadRelu: InProgress\n",
      "LossNotDecreasing: InProgress\n",
      "...\n",
      "2023-10-17 16:36:11 Starting - Preparing the instances for training......\n",
      "2023-10-17 16:37:13 Downloading - Downloading input data.........\n",
      "2023-10-17 16:38:52 Training - Downloading the training image........................\n",
      "2023-10-17 16:42:53 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-10-17 16:42:58,308 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-10-17 16:42:58,342 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-10-17 16:42:58,346 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-10-17 16:42:58,672 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"val\": \"/opt/ml/input/data/val\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": \"32\",\n",
      "        \"epochs\": \"3\",\n",
      "        \"learning-rate\": \"0.004563047309634722\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"val\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2023-10-17-16-35-23-026\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-053987932055/pytorch-training-2023-10-17-16-35-23-026/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_model1\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_model1.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":\"32\",\"epochs\":\"3\",\"learning-rate\":\"0.004563047309634722\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_model1.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\",\"val\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_model1\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-053987932055/pytorch-training-2023-10-17-16-35-23-026/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\",\"val\":\"/opt/ml/input/data/val\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":\"32\",\"epochs\":\"3\",\"learning-rate\":\"0.004563047309634722\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2023-10-17-16-35-23-026\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-053987932055/pytorch-training-2023-10-17-16-35-23-026/source/sourcedir.tar.gz\",\"module_name\":\"train_model1\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_model1.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"32\",\"--epochs\",\"3\",\"--learning-rate\",\"0.004563047309634722\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VAL=/opt/ml/input/data/val\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=32\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=3\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING-RATE=0.004563047309634722\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train_model1.py --batch-size 32 --epochs 3 --learning-rate 0.004563047309634722\u001b[0m\n",
      "\u001b[34m[2023-10-17 16:43:00.141 algo-1:27 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-10-17 16:43:00.189 algo-1:27 INFO profiler_config_parser.py:102] Using config at /opt/ml/input/config/profilerconfig.json.\u001b[0m\n",
      "\u001b[34m[2023-10-17 16:43:05.213 algo-1:27 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2023-10-17 16:43:05.215 algo-1:27 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2023-10-17 16:43:05.217 algo-1:27 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2023-10-17 16:43:05.218 algo-1:27 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2023-10-17 16:43:05.234 algo-1:27 INFO hook.py:591] name:fc.0.weight count_params:68096\u001b[0m\n",
      "\u001b[34m[2023-10-17 16:43:05.234 algo-1:27 INFO hook.py:591] name:fc.0.bias count_params:133\u001b[0m\n",
      "\u001b[34m[2023-10-17 16:43:05.234 algo-1:27 INFO hook.py:593] Total Trainable Params: 68229\u001b[0m\n",
      "\u001b[34mCreate train data loader\u001b[0m\n",
      "\u001b[34mCreate train data loader\u001b[0m\n",
      "\u001b[34m[2023-10-17 16:43:06.011 algo-1:27 INFO hook.py:425] Monitoring the collections: losses, relu_output, custom_collection\u001b[0m\n",
      "\u001b[34m[2023-10-17 16:43:06.013 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/prestepzero-*-start-1697560980190063.0_train-0-stepstart-1697560986013172.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2023-10-17 16:43:06.032 algo-1:27 INFO hook.py:488] Hook is writing from the hook with pid: 27\u001b[0m\n",
      "\u001b[34m[2023-10-17 16:43:08.496 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-0-stepstart-1697560986025175.0_train-0-forwardpassend-1697560988496350.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2023-10-17 16:43:09.338 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-0-forwardpassend-1697560988499783.5_train-1-stepstart-1697560989337799.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2023-10-17 16:43:10.213 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-1-stepstart-1697560989342639.5_train-1-forwardpassend-1697560990212628.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2023-10-17 16:43:10.622 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-1-forwardpassend-1697560990215156.8_train-2-stepstart-1697560990621422.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2023-10-17 16:43:11.355 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-2-stepstart-1697560990625508.5_train-2-forwardpassend-1697560991355429.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2023-10-17 16:43:11.961 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-2-forwardpassend-1697560991357465.2_train-3-stepstart-1697560991960043.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2023-10-17 16:43:12.618 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-3-stepstart-1697560991966098.8_train-3-forwardpassend-1697560992617746.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2023-10-17 16:43:13.432 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-3-forwardpassend-1697560992619666.5_train-4-stepstart-1697560993431240.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2023-10-17 16:43:14.152 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-4-stepstart-1697560993435907.2_train-4-forwardpassend-1697560994151849.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2023-10-17 16:43:14.642 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-4-forwardpassend-1697560994153848.2_train-5-stepstart-1697560994641240.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2023-10-17 16:43:15.311 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-5-stepstart-1697560994645572.5_train-5-forwardpassend-1697560995310688.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2023-10-17 16:43:15.878 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-5-forwardpassend-1697560995312572.0_train-6-stepstart-1697560995877290.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2023-10-17 16:43:16.519 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-6-stepstart-1697560995881223.0_train-6-forwardpassend-1697560996519539.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2023-10-17 16:43:16.981 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-6-forwardpassend-1697560996521314.8_train-7-stepstart-1697560996981046.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2023-10-17 16:43:17.632 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-7-stepstart-1697560996984801.2_train-7-forwardpassend-1697560997632362.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2023-10-17 16:43:17.966 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-7-forwardpassend-1697560997634204.2_train-8-stepstart-1697560997965706.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2023-10-17 16:43:18.647 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-8-stepstart-1697560997969954.2_train-8-forwardpassend-1697560998646564.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2023-10-17 16:43:19.080 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-8-forwardpassend-1697560998648448.2_train-9-stepstart-1697560999079333.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2023-10-17 16:43:19.724 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-9-stepstart-1697560999083030.8_train-9-forwardpassend-1697560999723837.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2023-10-17 16:43:20.250 algo-1:27 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/27-algo-1/train-9-forwardpassend-1697560999725740.0_train-10-stepstart-1697561000250019.5/python_stats.\u001b[0m\n",
      "\u001b[34mTrain : [3200/6680 (48%)] Loss: 2.077015\u001b[0m\n",
      "\u001b[34mTrain : [6400/6680 (96%)] Loss: 0.895863\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.0369, Accuracy: 564/836 (67%)\u001b[0m\n",
      "\u001b[34mTrain : [3200/6680 (48%)] Loss: 0.825297\u001b[0m\n",
      "\u001b[34mTrain : [6400/6680 (96%)] Loss: 1.513701\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.0347, Accuracy: 590/836 (71%)\u001b[0m\n",
      "\u001b[34mTrain : [3200/6680 (48%)] Loss: 0.557870\u001b[0m\n",
      "ClassImbalance: InProgress\n",
      "DeadRelu: InProgress\n",
      "LossNotDecreasing: Error\n",
      "\u001b[34mTrain : [6400/6680 (96%)] Loss: 0.712486\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.0354, Accuracy: 591/836 (71%)\u001b[0m\n",
      "\u001b[34mDownloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0.00/44.7M [00:00<?, ?B/s]#015 13%|█▎        | 6.00M/44.7M [00:00<00:00, 62.9MB/s]#015 27%|██▋       | 12.2M/44.7M [00:00<00:00, 64.1MB/s]#015 41%|████▏     | 18.4M/44.7M [00:00<00:00, 64.7MB/s]#015 55%|█████▌    | 24.8M/44.7M [00:00<00:00, 65.3MB/s]#015 70%|██████▉   | 31.1M/44.7M [00:00<00:00, 65.5MB/s]#015 84%|████████▎ | 37.4M/44.7M [00:00<00:00, 65.7MB/s]#015 98%|█████████▊| 43.7M/44.7M [00:00<00:00, 65.9MB/s]#015100%|██████████| 44.7M/44.7M [00:00<00:00, 65.3MB/s]\u001b[0m\n",
      "\u001b[34mINFO:__main__:Create train data loader\u001b[0m\n",
      "\u001b[34mINFO:__main__:Create train data loader\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train : [3200/6680 (48%)] Loss: 2.077015\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train : [6400/6680 (96%)] Loss: 0.895863\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.0369, Accuracy: 564/836 (67%)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train : [3200/6680 (48%)] Loss: 0.825297\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train : [6400/6680 (96%)] Loss: 1.513701\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.0347, Accuracy: 590/836 (71%)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train : [3200/6680 (48%)] Loss: 0.557870\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train : [6400/6680 (96%)] Loss: 0.712486\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.0354, Accuracy: 591/836 (71%)\u001b[0m\n",
      "\u001b[34m2023-10-17 16:47:52,552 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-10-17 16:48:36 Uploading - Uploading generated training model\n",
      "2023-10-17 16:48:55 Completed - Training job completed\n",
      "ClassImbalance: NoIssuesFound\n",
      "DeadRelu: NoIssuesFound\n",
      "LossNotDecreasing: Error\n",
      "Training seconds: 695\n",
      "Billable seconds: 695\n"
     ]
    }
   ],
   "source": [
    "estimator = PyTorch(\n",
    "    entry_point=\"train_model1.py\",\n",
    "    role=role,\n",
    "    py_version='py36',\n",
    "    framework_version=\"1.8\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.p3.2xlarge\",\n",
    "    hyperparameters = hyperparameters,\n",
    "    rules=[class_imbalance_rule, dead_relu_rule, loss_not_decreasing_rule],\n",
    "    debugger_hook_config=debugger_hook_config,\n",
    "    profiler_config=profiler_config\n",
    ")\n",
    "\n",
    "estimator.fit({\"train\": train_path,\n",
    "               \"val\": valid_path,  # the key has to be \"val\"\n",
    "               \"test\": test_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 's3_output_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatest_job_tensorboard_artifacts_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/estimator.py:1219\u001b[0m, in \u001b[0;36mEstimatorBase.latest_job_tensorboard_artifacts_path\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_latest_training_job(\n\u001b[1;32m   1214\u001b[0m     error_message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mCannot get the TensorBoard artifacts path.\u001b[39m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;124mThe Estimator is not associated with a training job.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m   1216\u001b[0m )\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebugger_hook_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m-> 1219\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensorboard_output_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ms3_output_path\u001b[49m,\n\u001b[1;32m   1220\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_training_job\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m   1221\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorboard-output\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1222\u001b[0m     )\n\u001b[1;32m   1223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 's3_output_path'"
     ]
    }
   ],
   "source": [
    "estimator.latest_job_tensorboard_artifacts_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-17 16:51:58.987 ip-172-16-103-235.ec2.internal:9760 INFO s3_trial.py:42] Loading trial debug-output at path s3://sagemaker-us-east-1-053987932055/pytorch-training-2023-10-17-15-21-19-569/debug-output\n",
      "[2023-10-17 16:51:59.288 ip-172-16-103-235.ec2.internal:9760 WARNING s3handler.py:183] Encountered the exception An error occurred while reading from response stream: ('Connection broken: IncompleteRead(0 bytes read, 1834 more expected)', IncompleteRead(0 bytes read, 1834 more expected)) while reading s3://sagemaker-us-east-1-053987932055/pytorch-training-2023-10-17-15-21-19-569/debug-output/index/000000000/000000000000_worker_0.json . Will retry now\n"
     ]
    }
   ],
   "source": [
    "import smdebug\n",
    "from smdebug.trials import create_trial\n",
    "from smdebug.core.modes import ModeKeys\n",
    "\n",
    "trial = create_trial('s3://sagemaker-us-east-1-053987932055/pytorch-training-2023-10-17-15-21-19-569/debug-output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CrossEntropyLoss_output_0',\n",
       " 'gradient/ResNet_fc.0.bias',\n",
       " 'gradient/ResNet_fc.0.weight',\n",
       " 'layer1.0.relu_input_0',\n",
       " 'layer1.0.relu_input_1',\n",
       " 'layer1.1.relu_input_0',\n",
       " 'layer1.1.relu_input_1',\n",
       " 'layer2.0.relu_input_0',\n",
       " 'layer2.0.relu_input_1',\n",
       " 'layer2.1.relu_input_0',\n",
       " 'layer2.1.relu_input_1',\n",
       " 'layer3.0.relu_input_0',\n",
       " 'layer3.0.relu_input_1',\n",
       " 'layer3.1.relu_input_0',\n",
       " 'layer3.1.relu_input_1',\n",
       " 'layer4.0.relu_input_0',\n",
       " 'layer4.0.relu_input_1',\n",
       " 'layer4.1.relu_input_0',\n",
       " 'layer4.1.relu_input_1',\n",
       " 'relu_input_0']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial.tensor_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data(trial, tname, mode):\n",
    "    tensor = trial.tensor(tname)\n",
    "    steps = tensor.steps(mode=mode)\n",
    "    vals = []\n",
    "    for s in steps:\n",
    "        vals.append(tensor.value(s, mode=mode))\n",
    "    return steps, vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'str'.\n`np.str` was a deprecated alias for the builtin `str`. To avoid this error in existing code, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCrossEntropyLoss_output_0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEVAL\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[52], line 6\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(trial, tname, mode)\u001b[0m\n\u001b[1;32m      4\u001b[0m vals \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m steps:\n\u001b[0;32m----> 6\u001b[0m     vals\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m steps, vals\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/smdebug/core/tensor.py:273\u001b[0m, in \u001b[0;36mTensor.value\u001b[0;34m(self, step_num, mode, worker)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m s\u001b[38;5;241m.\u001b[39mvalue\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m s\u001b[38;5;241m.\u001b[39mlocation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 273\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_tensor_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache:\n\u001b[1;32m    275\u001b[0m         s\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m=\u001b[39m value\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/smdebug/core/index_reader.py:309\u001b[0m, in \u001b[0;36mS3IndexReader.fetch_tensor_value\u001b[0;34m(self, tensor_location)\u001b[0m\n\u001b[1;32m    307\u001b[0m res \u001b[38;5;241m=\u001b[39m S3Handler\u001b[38;5;241m.\u001b[39mget_objects(request)\n\u001b[1;32m    308\u001b[0m tr \u001b[38;5;241m=\u001b[39m TensorReader(res[\u001b[38;5;241m0\u001b[39m])  \u001b[38;5;66;03m# Access the only element in res\u001b[39;00m\n\u001b[0;32m--> 309\u001b[0m tensor_tuple \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Access the only element in the list\u001b[39;00m\n\u001b[1;32m    310\u001b[0m tensor_name, step, tensor_data, mode, mode_step \u001b[38;5;241m=\u001b[39m tensor_tuple\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensor_data\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/smdebug/core/tfrecord/tensor_reader.py:67\u001b[0m, in \u001b[0;36mTensorReader.read_tensors\u001b[0;34m(self, check)\u001b[0m\n\u001b[1;32m     65\u001b[0m tensor_name \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mtag\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# We have found the right tensor at the right step\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m tensor_data \u001b[38;5;241m=\u001b[39m \u001b[43mget_tensor_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m mode, mode_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_mode_modestep(step, v\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mplugin_data)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m (tensor_name, step, tensor_data, mode, mode_step)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/smdebug/core/tfevent/event_file_reader.py:60\u001b[0m, in \u001b[0;36mget_tensor_data\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m     57\u001b[0m         res\u001b[38;5;241m.\u001b[39mappend(r)\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(res)\n\u001b[0;32m---> 60\u001b[0m dtype \u001b[38;5;241m=\u001b[39m \u001b[43mas_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# dtype = tensor_dtype.as_numpy_dtype\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# dtype = np.float32\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# print(\"FOO=\", tensor)\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# print(\"FOOTYPE=\", tensor.dtype)\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mtensor_content:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/smdebug/core/tfevent/event_file_reader.py:40\u001b[0m, in \u001b[0;36mas_dtype\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mas_dtype\u001b[39m(t):\n\u001b[1;32m     33\u001b[0m     _INTERN_TABLE \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     34\u001b[0m         types_pb2\u001b[38;5;241m.\u001b[39mDT_HALF: np\u001b[38;5;241m.\u001b[39mfloat16,\n\u001b[1;32m     35\u001b[0m         types_pb2\u001b[38;5;241m.\u001b[39mDT_FLOAT: np\u001b[38;5;241m.\u001b[39mfloat32,\n\u001b[1;32m     36\u001b[0m         types_pb2\u001b[38;5;241m.\u001b[39mDT_DOUBLE: np\u001b[38;5;241m.\u001b[39mfloat64,\n\u001b[1;32m     37\u001b[0m         types_pb2\u001b[38;5;241m.\u001b[39mDT_INT8: np\u001b[38;5;241m.\u001b[39muint8,\n\u001b[1;32m     38\u001b[0m         types_pb2\u001b[38;5;241m.\u001b[39mDT_INT32: np\u001b[38;5;241m.\u001b[39mint32,\n\u001b[1;32m     39\u001b[0m         types_pb2\u001b[38;5;241m.\u001b[39mDT_INT64: np\u001b[38;5;241m.\u001b[39mint64,\n\u001b[0;32m---> 40\u001b[0m         types_pb2\u001b[38;5;241m.\u001b[39mDT_STRING: \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m,\n\u001b[1;32m     41\u001b[0m         types_pb2\u001b[38;5;241m.\u001b[39mDT_BOOL: np\u001b[38;5;241m.\u001b[39mbool,\n\u001b[1;32m     42\u001b[0m         types_pb2\u001b[38;5;241m.\u001b[39mDT_UINT8: np\u001b[38;5;241m.\u001b[39muint8,\n\u001b[1;32m     43\u001b[0m         types_pb2\u001b[38;5;241m.\u001b[39mDT_COMPLEX128: np\u001b[38;5;241m.\u001b[39mcomplex128,\n\u001b[1;32m     44\u001b[0m     }\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _INTERN_TABLE[t]\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/numpy/__init__.py:305\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    300\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# Importing Tester requires importing all of UnitTest which is not a\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;66;03m# cheap import Since it is mainly used in test suits, we lazy import it\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;66;03m# here to save on the order of 10 ms of import time for most users\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# The previous way Tester was imported also had a side effect of adding\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;66;03m# the full `numpy.testing` namespace\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'str'.\n`np.str` was a deprecated alias for the builtin `str`. To avoid this error in existing code, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "get_data(trial, 'CrossEntropyLoss_output_0', mode=ModeKeys.EVAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'str'.\n`np.str` was a deprecated alias for the builtin `str`. To avoid this error in existing code, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCrossEntropyLoss_output_0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEVAL\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mvalues()\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/smdebug/core/tensor.py:264\u001b[0m, in \u001b[0;36mTensor.values\u001b[0;34m(self, mode, worker)\u001b[0m\n\u001b[1;32m    262\u001b[0m res \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps(mode\u001b[38;5;241m=\u001b[39mmode):\n\u001b[0;32m--> 264\u001b[0m     res[step] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/smdebug/core/tensor.py:273\u001b[0m, in \u001b[0;36mTensor.value\u001b[0;34m(self, step_num, mode, worker)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m s\u001b[38;5;241m.\u001b[39mvalue\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m s\u001b[38;5;241m.\u001b[39mlocation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 273\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_tensor_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache:\n\u001b[1;32m    275\u001b[0m         s\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m=\u001b[39m value\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/smdebug/core/index_reader.py:309\u001b[0m, in \u001b[0;36mS3IndexReader.fetch_tensor_value\u001b[0;34m(self, tensor_location)\u001b[0m\n\u001b[1;32m    307\u001b[0m res \u001b[38;5;241m=\u001b[39m S3Handler\u001b[38;5;241m.\u001b[39mget_objects(request)\n\u001b[1;32m    308\u001b[0m tr \u001b[38;5;241m=\u001b[39m TensorReader(res[\u001b[38;5;241m0\u001b[39m])  \u001b[38;5;66;03m# Access the only element in res\u001b[39;00m\n\u001b[0;32m--> 309\u001b[0m tensor_tuple \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Access the only element in the list\u001b[39;00m\n\u001b[1;32m    310\u001b[0m tensor_name, step, tensor_data, mode, mode_step \u001b[38;5;241m=\u001b[39m tensor_tuple\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensor_data\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/smdebug/core/tfrecord/tensor_reader.py:67\u001b[0m, in \u001b[0;36mTensorReader.read_tensors\u001b[0;34m(self, check)\u001b[0m\n\u001b[1;32m     65\u001b[0m tensor_name \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mtag\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# We have found the right tensor at the right step\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m tensor_data \u001b[38;5;241m=\u001b[39m \u001b[43mget_tensor_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m mode, mode_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_mode_modestep(step, v\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mplugin_data)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m (tensor_name, step, tensor_data, mode, mode_step)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/smdebug/core/tfevent/event_file_reader.py:60\u001b[0m, in \u001b[0;36mget_tensor_data\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m     57\u001b[0m         res\u001b[38;5;241m.\u001b[39mappend(r)\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(res)\n\u001b[0;32m---> 60\u001b[0m dtype \u001b[38;5;241m=\u001b[39m \u001b[43mas_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# dtype = tensor_dtype.as_numpy_dtype\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# dtype = np.float32\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# print(\"FOO=\", tensor)\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# print(\"FOOTYPE=\", tensor.dtype)\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mtensor_content:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/smdebug/core/tfevent/event_file_reader.py:40\u001b[0m, in \u001b[0;36mas_dtype\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mas_dtype\u001b[39m(t):\n\u001b[1;32m     33\u001b[0m     _INTERN_TABLE \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     34\u001b[0m         types_pb2\u001b[38;5;241m.\u001b[39mDT_HALF: np\u001b[38;5;241m.\u001b[39mfloat16,\n\u001b[1;32m     35\u001b[0m         types_pb2\u001b[38;5;241m.\u001b[39mDT_FLOAT: np\u001b[38;5;241m.\u001b[39mfloat32,\n\u001b[1;32m     36\u001b[0m         types_pb2\u001b[38;5;241m.\u001b[39mDT_DOUBLE: np\u001b[38;5;241m.\u001b[39mfloat64,\n\u001b[1;32m     37\u001b[0m         types_pb2\u001b[38;5;241m.\u001b[39mDT_INT8: np\u001b[38;5;241m.\u001b[39muint8,\n\u001b[1;32m     38\u001b[0m         types_pb2\u001b[38;5;241m.\u001b[39mDT_INT32: np\u001b[38;5;241m.\u001b[39mint32,\n\u001b[1;32m     39\u001b[0m         types_pb2\u001b[38;5;241m.\u001b[39mDT_INT64: np\u001b[38;5;241m.\u001b[39mint64,\n\u001b[0;32m---> 40\u001b[0m         types_pb2\u001b[38;5;241m.\u001b[39mDT_STRING: \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m,\n\u001b[1;32m     41\u001b[0m         types_pb2\u001b[38;5;241m.\u001b[39mDT_BOOL: np\u001b[38;5;241m.\u001b[39mbool,\n\u001b[1;32m     42\u001b[0m         types_pb2\u001b[38;5;241m.\u001b[39mDT_UINT8: np\u001b[38;5;241m.\u001b[39muint8,\n\u001b[1;32m     43\u001b[0m         types_pb2\u001b[38;5;241m.\u001b[39mDT_COMPLEX128: np\u001b[38;5;241m.\u001b[39mcomplex128,\n\u001b[1;32m     44\u001b[0m     }\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _INTERN_TABLE[t]\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/numpy/__init__.py:305\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    300\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# Importing Tester requires importing all of UnitTest which is not a\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;66;03m# cheap import Since it is mainly used in test suits, we lazy import it\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;66;03m# here to save on the order of 10 ms of import time for most users\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# The previous way Tester was imported also had a side effect of adding\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;66;03m# the full `numpy.testing` namespace\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'str'.\n`np.str` was a deprecated alias for the builtin `str`. To avoid this error in existing code, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "trial.tensor('CrossEntropyLoss_output_0').values(mode=ModeKeys.EVAL).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/smdebug/core/tfevent/event_file_reader.py:40: FutureWarning: In the future `np.str` will be defined as the corresponding NumPy scalar.\n",
      "  types_pb2.DT_STRING: np.str,\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'str'.\n`np.str` was a deprecated alias for the builtin `str`. To avoid this error in existing code, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSteps\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(trial\u001b[38;5;241m.\u001b[39msteps(mode\u001b[38;5;241m=\u001b[39mmodes\u001b[38;5;241m.\u001b[39mTRAIN),\n\u001b[0;32m---> 10\u001b[0m          \u001b[38;5;28mlist\u001b[39m(\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCrossEntropyLoss_output_0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[1;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/smdebug/core/tensor.py:264\u001b[0m, in \u001b[0;36mTensor.values\u001b[0;34m(self, mode, worker)\u001b[0m\n\u001b[1;32m    262\u001b[0m res \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps(mode\u001b[38;5;241m=\u001b[39mmode):\n\u001b[0;32m--> 264\u001b[0m     res[step] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/smdebug/core/tensor.py:273\u001b[0m, in \u001b[0;36mTensor.value\u001b[0;34m(self, step_num, mode, worker)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m s\u001b[38;5;241m.\u001b[39mvalue\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m s\u001b[38;5;241m.\u001b[39mlocation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 273\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_tensor_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache:\n\u001b[1;32m    275\u001b[0m         s\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m=\u001b[39m value\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/smdebug/core/index_reader.py:309\u001b[0m, in \u001b[0;36mS3IndexReader.fetch_tensor_value\u001b[0;34m(self, tensor_location)\u001b[0m\n\u001b[1;32m    307\u001b[0m res \u001b[38;5;241m=\u001b[39m S3Handler\u001b[38;5;241m.\u001b[39mget_objects(request)\n\u001b[1;32m    308\u001b[0m tr \u001b[38;5;241m=\u001b[39m TensorReader(res[\u001b[38;5;241m0\u001b[39m])  \u001b[38;5;66;03m# Access the only element in res\u001b[39;00m\n\u001b[0;32m--> 309\u001b[0m tensor_tuple \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Access the only element in the list\u001b[39;00m\n\u001b[1;32m    310\u001b[0m tensor_name, step, tensor_data, mode, mode_step \u001b[38;5;241m=\u001b[39m tensor_tuple\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensor_data\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/smdebug/core/tfrecord/tensor_reader.py:67\u001b[0m, in \u001b[0;36mTensorReader.read_tensors\u001b[0;34m(self, check)\u001b[0m\n\u001b[1;32m     65\u001b[0m tensor_name \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mtag\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# We have found the right tensor at the right step\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m tensor_data \u001b[38;5;241m=\u001b[39m \u001b[43mget_tensor_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m mode, mode_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_mode_modestep(step, v\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mplugin_data)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m (tensor_name, step, tensor_data, mode, mode_step)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/smdebug/core/tfevent/event_file_reader.py:60\u001b[0m, in \u001b[0;36mget_tensor_data\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m     57\u001b[0m         res\u001b[38;5;241m.\u001b[39mappend(r)\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(res)\n\u001b[0;32m---> 60\u001b[0m dtype \u001b[38;5;241m=\u001b[39m \u001b[43mas_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# dtype = tensor_dtype.as_numpy_dtype\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# dtype = np.float32\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# print(\"FOO=\", tensor)\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# print(\"FOOTYPE=\", tensor.dtype)\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mtensor_content:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/smdebug/core/tfevent/event_file_reader.py:40\u001b[0m, in \u001b[0;36mas_dtype\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mas_dtype\u001b[39m(t):\n\u001b[1;32m     33\u001b[0m     _INTERN_TABLE \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     34\u001b[0m         types_pb2\u001b[38;5;241m.\u001b[39mDT_HALF: np\u001b[38;5;241m.\u001b[39mfloat16,\n\u001b[1;32m     35\u001b[0m         types_pb2\u001b[38;5;241m.\u001b[39mDT_FLOAT: np\u001b[38;5;241m.\u001b[39mfloat32,\n\u001b[1;32m     36\u001b[0m         types_pb2\u001b[38;5;241m.\u001b[39mDT_DOUBLE: np\u001b[38;5;241m.\u001b[39mfloat64,\n\u001b[1;32m     37\u001b[0m         types_pb2\u001b[38;5;241m.\u001b[39mDT_INT8: np\u001b[38;5;241m.\u001b[39muint8,\n\u001b[1;32m     38\u001b[0m         types_pb2\u001b[38;5;241m.\u001b[39mDT_INT32: np\u001b[38;5;241m.\u001b[39mint32,\n\u001b[1;32m     39\u001b[0m         types_pb2\u001b[38;5;241m.\u001b[39mDT_INT64: np\u001b[38;5;241m.\u001b[39mint64,\n\u001b[0;32m---> 40\u001b[0m         types_pb2\u001b[38;5;241m.\u001b[39mDT_STRING: \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m,\n\u001b[1;32m     41\u001b[0m         types_pb2\u001b[38;5;241m.\u001b[39mDT_BOOL: np\u001b[38;5;241m.\u001b[39mbool,\n\u001b[1;32m     42\u001b[0m         types_pb2\u001b[38;5;241m.\u001b[39mDT_UINT8: np\u001b[38;5;241m.\u001b[39muint8,\n\u001b[1;32m     43\u001b[0m         types_pb2\u001b[38;5;241m.\u001b[39mDT_COMPLEX128: np\u001b[38;5;241m.\u001b[39mcomplex128,\n\u001b[1;32m     44\u001b[0m     }\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _INTERN_TABLE[t]\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/numpy/__init__.py:305\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    300\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# Importing Tester requires importing all of UnitTest which is not a\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;66;03m# cheap import Since it is mainly used in test suits, we lazy import it\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;66;03m# here to save on the order of 10 ms of import time for most users\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# The previous way Tester was imported also had a side effect of adding\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;66;03m# the full `numpy.testing` namespace\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'str'.\n`np.str` was a deprecated alias for the builtin `str`. To avoid this error in existing code, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABmAAAAHFCAYAAADlizaSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAv80lEQVR4nO3df5SWdZ3/8dcNyIxpMyYmPwwRU5MiaRkWBOLbaomLrkW6gnmK/NVGWqyQriEnDLJl9axWZqAlSJ7QiPyxbIejTLUlih6VBdeCox4lB3OQA6wz+CN+3t8/PMzuLKAMXsPt0ONxzn1O85nruu/37R9X6JPPdZXK5XI5AAAAAAAAFKZTpQcAAAAAAAA40AgwAAAAAAAABRNgAAAAAAAACibAAAAAAAAAFEyAAQAAAAAAKJgAAwAAAAAAUDABBgAAAAAAoGACDAAAAAAAQMEEGAAAAAAAgIIJMAAAAAAAAAWraIB58MEHc9ZZZ6VXr14plUq577773vac3/3ud6mrq0t1dXWOPfbY3HLLLe0/KAAAAAAAQBtUNMC89tprGTBgQG6++ea9On716tU544wzMmLEiCxfvjxXX311JkyYkLvvvrudJwUAAAAAANh7pXK5XK70EElSKpVy7733ZvTo0Xs85qqrrsrChQuzatWqlrXx48fnySefzCOPPLIfpgQAAAAAAHh7XSo9QFs88sgjGTlyZKu1008/PbNnz87WrVtz0EEH7XLO5s2bs3nz5pafd+zYkY0bN6Zbt24plUrtPjMAAAAAAPDuVS6Xs2nTpvTq1SudOhV347AOFWDWrl2b7t27t1rr3r17tm3blvXr16dnz567nDNjxoxMmzZtf40IAAAAAAB0QGvWrMkHPvCBwt6vQwWYJLvsWtl5B7U97WaZPHlyJk2a1PJzU1NTjj766KxZsyY1NTXtNygAAAAAAPCu19zcnN69e+e9731voe/boQJMjx49snbt2lZr69atS5cuXdKtW7fdnlNVVZWqqqpd1mtqagQYAAAAAAAgyZ43euyr4m5mth8MHTo09fX1rdYWL16cQYMG7fb5LwAAAAAAAJVQ0QDz6quvZsWKFVmxYkWSZPXq1VmxYkUaGhqSvHn7sHHjxrUcP378+LzwwguZNGlSVq1alTlz5mT27Nm54oorKjE+AAAAAADAblX0FmRPPPFETjnllJafdz6r5Ytf/GLmzp2bxsbGlhiTJH379s2iRYsyceLE/PCHP0yvXr1y00035ZxzztnvswMAAAAAAOxJqbzzKfZ/IZqbm1NbW5umpibPgAEAAAAAgL9w7dUNOtQzYAAAAAAAADoCAQYAAAAAAKBgAgwAAAAAAEDBBBgAAAAAAICCCTAAAAAAAAAFE2AAAAAAAAAKJsAAAAAAAAAUTIABAAAAAAAomAADAAAAAABQMAEGAAAAAACgYAIMAAAAAABAwQQYAAAAAACAggkwAAAAAAAABRNgAAAAAAAACibAAAAAAAAAFEyAAQAAAAAAKJgAAwAAAAAAUDABBgAAAAAAoGACDAAAAAAAQMEEGAAAAAAAgIIJMAAAAAAAAAUTYAAAAAAAAAomwAAAAAAAABRMgAEAAAAAACiYAAMAAAAAAFAwAQYAAAAAAKBgAgwAAAAAAEDBBBgAAAAAAICCCTAAAAAAAAAFE2AAAAAAAAAKJsAAAAAAAAAUTIABAAAAAAAomAADAAAAAABQMAEGAAAAAACgYAIMAAAAAABAwQQYAAAAAACAggkwAAAAAAAABRNgAAAAAAAACibAAAAAAAAAFEyAAQAAAAAAKJgAAwAAAAAAUDABBgAAAAAAoGACDAAAAAAAQMEEGAAAAAAAgIIJMAAAAAAAAAUTYAAAAAAAAAomwAAAAAAAABRMgAEAAAAAACiYAAMAAAAAAFAwAQYAAAAAAKBgAgwAAAAAAEDBBBgAAAAAAICCCTAAAAAAAAAFE2AAAAAAAAAKJsAAAAAAAAAUTIABAAAAAAAomAADAAAAAABQMAEGAAAAAACgYAIMAAAAAABAwQQYAAAAAACAggkwAAAAAAAABRNgAAAAAAAACibAAAAAAAAAFEyAAQAAAAAAKJgAAwAAAAAAUDABBgAAAAAAoGAVDzAzZ85M3759U11dnbq6uixZsuQtj583b14GDBiQ97znPenZs2cuvPDCbNiwYT9NCwAAAAAA8PYqGmDmz5+fyy+/PFOmTMny5cszYsSIjBo1Kg0NDbs9/qGHHsq4ceNy8cUX5w9/+EMWLFiQxx9/PJdccsl+nhwAAAAAAGDPKhpgbrzxxlx88cW55JJL0q9fv3zve99L7969M2vWrN0e/+ijj+aYY47JhAkT0rdv33z84x/Pl7/85TzxxBP7eXIAAAAAAIA9q1iA2bJlS5YtW5aRI0e2Wh85cmSWLl2623OGDRuWF198MYsWLUq5XM7LL7+cX/ziFznzzDP3+DmbN29Oc3NzqxcAAAAAAEB7qliAWb9+fbZv357u3bu3Wu/evXvWrl2723OGDRuWefPmZezYsenatWt69OiRww47LD/4wQ/2+DkzZsxIbW1ty6t3796Ffg8AAAAAAID/q6K3IEuSUqnU6udyubzL2k4rV67MhAkTMnXq1Cxbtiz3339/Vq9enfHjx+/x/SdPnpympqaW15o1awqdHwAAAAAA4P/qUqkPPuKII9K5c+dddrusW7dul10xO82YMSPDhw/PlVdemSQ56aSTcsghh2TEiBG59tpr07Nnz13OqaqqSlVVVfFfAAAAAAAAYA8qtgOma9euqaurS319fav1+vr6DBs2bLfnvP766+nUqfXInTt3TvLmzhkAAAAAAIB3g4regmzSpEm57bbbMmfOnKxatSoTJ05MQ0NDyy3FJk+enHHjxrUcf9ZZZ+Wee+7JrFmz8vzzz+fhhx/OhAkTMnjw4PTq1atSXwMAAAAAAKCVit2CLEnGjh2bDRs2ZPr06WlsbEz//v2zaNGi9OnTJ0nS2NiYhoaGluMvuOCCbNq0KTfffHO+/vWv57DDDsupp56a6667rlJfAQAAAAAAYBel8l/Yvbuam5tTW1ubpqam1NTUVHocAAAAAACggtqrG1T0FmQAAAAAAAAHIgEGAAAAAACgYAIMAAAAAABAwQQYAAAAAACAggkwAAAAAAAABRNgAAAAAAAACibAAAAAAAAAFEyAAQAAAAAAKJgAAwAAAAAAUDABBgAAAAAAoGACDAAAAAAAQMEEGAAAAAAAgIIJMAAAAAAAAAUTYAAAAAAAAAomwAAAAAAAABRMgAEAAAAAACiYAAMAAAAAAFAwAQYAAAAAAKBgAgwAAAAAAEDBBBgAAAAAAICCCTAAAAAAAAAFE2AAAAAAAAAKJsAAAAAAAAAUTIABAAAAAAAomAADAAAAAABQMAEGAAAAAACgYAIMAAAAAABAwQQYAAAAAACAggkwAAAAAAAABRNgAAAAAAAACibAAAAAAAAAFEyAAQAAAAAAKJgAAwAAAAAAUDABBgAAAAAAoGACDAAAAAAAQMEEGAAAAAAAgIIJMAAAAAAAAAUTYAAAAAAAAAomwAAAAAAAABRMgAEAAAAAACiYAAMAAAAAAFAwAQYAAAAAAKBgAgwAAAAAAEDBBBgAAAAAAICCCTAAAAAAAAAFE2AAAAAAAAAKJsAAAAAAAAAUTIABAAAAAAAomAADAAAAAABQMAEGAAAAAACgYAIMAAAAAABAwQQYAAAAAACAggkwAAAAAAAABRNgAAAAAAAACibAAAAAAAAAFEyAAQAAAAAAKJgAAwAAAAAAUDABBgAAAAAAoGACDAAAAAAAQMEEGAAAAAAAgIIJMAAAAAAAAAUTYAAAAAAAAAomwAAAAAAAABRMgAEAAAAAACiYAAMAAAAAAFAwAQYAAAAAAKBgFQ8wM2fOTN++fVNdXZ26urosWbLkLY/fvHlzpkyZkj59+qSqqiof/OAHM2fOnP00LQAAAAAAwNvrUskPnz9/fi6//PLMnDkzw4cPz6233ppRo0Zl5cqVOfroo3d7zpgxY/Lyyy9n9uzZOe6447Ju3bps27ZtP08OAAAAAACwZ6VyuVyu1IcPGTIkAwcOzKxZs1rW+vXrl9GjR2fGjBm7HH///ffnvPPOy/PPP5/DDz98nz6zubk5tbW1aWpqSk1NzT7PDgAAAAAAdHzt1Q0qdguyLVu2ZNmyZRk5cmSr9ZEjR2bp0qW7PWfhwoUZNGhQrr/++hx11FE54YQTcsUVV+SNN97Y4+ds3rw5zc3NrV4AAAAAAADtqWK3IFu/fn22b9+e7t27t1rv3r171q5du9tznn/++Tz00EOprq7Ovffem/Xr1+fSSy/Nxo0b9/gcmBkzZmTatGmFzw8AAAAAALAnFdsBs1OpVGr1c7lc3mVtpx07dqRUKmXevHkZPHhwzjjjjNx4442ZO3fuHnfBTJ48OU1NTS2vNWvWFP4dAAAAAAAA/reK7YA54ogj0rlz5112u6xbt26XXTE79ezZM0cddVRqa2tb1vr165dyuZwXX3wxxx9//C7nVFVVpaqqqtjhAQAAAAAA3kLFdsB07do1dXV1qa+vb7VeX1+fYcOG7fac4cOH56WXXsqrr77asvbMM8+kU6dO+cAHPtCu8wIAAAAAAOytit6CbNKkSbntttsyZ86crFq1KhMnTkxDQ0PGjx+f5M3bh40bN67l+PPPPz/dunXLhRdemJUrV+bBBx/MlVdemYsuuigHH3xwpb4GAAAAAABAKxW7BVmSjB07Nhs2bMj06dPT2NiY/v37Z9GiRenTp0+SpLGxMQ0NDS3HH3rooamvr8/Xvva1DBo0KN26dcuYMWNy7bXXVuorAAAAAAAA7KJULpfLbTlhzZo1KZVKLbf8euyxx3LnnXfmwx/+cP7hH/6hXYYsUnNzc2pra9PU1JSamppKjwMAAAAAAFRQe3WDNt+C7Pzzz89//Md/JEnWrl2b0047LY899liuvvrqTJ8+vbDBAAAAAAAAOqo2B5jf//73GTx4cJLk5z//efr375+lS5fmzjvvzNy5c4ueDwAAAAAAoMNpc4DZunVrqqqqkiS/+tWv8ulPfzpJcuKJJ6axsbHY6QAAAAAAADqgNgeYj3zkI7nllluyZMmS1NfX52//9m+TJC+99FK6detW+IAAAAAAAAAdTZsDzHXXXZdbb701f/M3f5PPfe5zGTBgQJJk4cKFLbcmAwAAAAAA+EtWKpfL5baetH379jQ3N+d973tfy9of//jHvOc978mRRx5Z6IBFa25uTm1tbZqamlJTU1PpcQAAAAAAgApqr27Q5h0wb7zxRjZv3twSX1544YV873vfy9NPP/2ujy8AAAAAAAD7Q5sDzGc+85nccccdSZJXXnklQ4YMyQ033JDRo0dn1qxZhQ8IAAAAAADQ0bQ5wPznf/5nRowYkST5xS9+ke7du+eFF17IHXfckZtuuqnwAQEAAAAAADqaNgeY119/Pe9973uTJIsXL87ZZ5+dTp065eSTT84LL7xQ+IAAAAAAAAAdTZsDzHHHHZf77rsva9asyQMPPJCRI0cmSdatW+eh9gAAAAAAANmHADN16tRcccUVOeaYYzJ48OAMHTo0yZu7Yf7qr/6q8AEBAAAAAAA6mlK5XC639aS1a9emsbExAwYMSKdObzacxx57LDU1NTnxxBMLH7JIzc3Nqa2tTVNTkx07AAAAAADwF669ukGXfTmpR48e6dGjR1588cWUSqUcddRRGTx4cGFDAQAAAAAAdGRtvgXZjh07Mn369NTW1qZPnz45+uijc9hhh+Xb3/52duzY0R4zAgAAAAAAdCht3gEzZcqUzJ49O//yL/+S4cOHp1wu5+GHH863vvWt/PnPf853vvOd9pgTAAAAAACgw2jzM2B69eqVW265JZ/+9Kdbrf/bv/1bLr300vzpT38qdMCieQYMAAAAAACwU3t1gzbfgmzjxo058cQTd1k/8cQTs3HjxkKGAgAAAAAA6MjaHGAGDBiQm2++eZf1m2++OQMGDChkKAAAAAAAgI6szc+Auf7663PmmWfmV7/6VYYOHZpSqZSlS5dmzZo1WbRoUXvMCAAAAAAA0KG0eQfMJz7xiTzzzDP57Gc/m1deeSUbN27M2WefnaeffjojRoxojxkBAAAAAAA6lFK5XC4X8UZr1qzJNddckzlz5hTxdu2mvR6mAwAAAAAAdDzt1Q3avANmTzZu3Jif/OQnRb0dAAAAAABAh1VYgAEAAAAAAOBNAgwAAAAAAEDBBBgAAAAAAICCddnbA88+++y3/P0rr7zyTmcBAAAAAAA4IOx1gKmtrX3b348bN+4dDwQAAAAAANDR7XWAuf3229tzDgAAAAAAgAOGZ8AAAAAAAAAUTIABAAAAAAAomAADAAAAAABQMAEGAAAAAACgYAIMAAAAAABAwbrsy0nPPPNMfvvb32bdunXZsWNHq99NnTq1kMEAAAAAAAA6qjYHmB//+Mf5yle+kiOOOCI9evRIqVRq+V2pVBJgAAAAAACAv3htDjDXXnttvvOd7+Sqq65qj3kAAAAAAAA6vDY/A+a///u/c+6557bHLAAAAAAAAAeENgeYc889N4sXL26PWQAAAAAAAA4Ibb4F2XHHHZdvfvObefTRR/PRj340Bx10UKvfT5gwobDhAAAAAAAAOqJSuVwut+WEvn377vnNSqU8//zz73io9tTc3Jza2to0NTWlpqam0uMAAAAAAAAV1F7doM07YFavXl3YhwMAAAAAAByI2vwMGAAAAAAAAN7aXu2AmTRpUr797W/nkEMOyaRJk97y2BtvvLGQwQAAAAAAADqqvQowy5cvz9atW1v+956USqVipgIAAAAAAOjASuVyuVzpIfan9nqYDgAAAAAA0PG0VzfwDBgAAAAAAICC7dUtyP6vxx9/PAsWLEhDQ0O2bNnS6nf33HNPIYMBAAAAAAB0VG3eAfOzn/0sw4cPz8qVK3Pvvfdm69atWblyZX7zm9+ktra2PWYEAAAAAADoUNocYP75n/853/3ud/PLX/4yXbt2zfe///2sWrUqY8aMydFHH90eMwIAAAAAAHQobQ4wzz33XM4888wkSVVVVV577bWUSqVMnDgxP/rRjwofEAAAAAAAoKNpc4A5/PDDs2nTpiTJUUcdld///vdJkldeeSWvv/56sdMBAAAAAAB0QF3aesKIESNSX1+fj370oxkzZkz+8R//Mb/5zW9SX1+fT37yk+0xIwAAAAAAQIfS5gBz8803589//nOSZPLkyTnooIPy0EMP5eyzz843v/nNwgcEAAAAAADoaErlcrm8twdv27Yt8+bNy+mnn54ePXq051ztprm5ObW1tWlqakpNTU2lxwEAAAAAACqovbpBm54B06VLl3zlK1/J5s2bCxsAAAAAAADgQNOmAJMkQ4YMyfLly9tjFgAAAAAAgANCm58Bc+mll+brX/96XnzxxdTV1eWQQw5p9fuTTjqpsOEAAAAAAAA6or1+BsxFF12U733veznssMN2fZNSKeVyOaVSKdu3by96xkJ5BgwAAAAAALBTe3WDvQ4wnTt3TmNjY9544423PK5Pnz6FDNZeBBgAAAAAAGCn9uoGe30Lsp2d5t0eWAAAAAAAACqtU1sOLpVK7TUHAAAAAADAAWOvd8AkyQknnPC2EWbjxo3vaCAAAAAAAICOrk0BZtq0aamtrW2vWQAAAAAAAA4IbQow5513Xo488sj2mgUAAAAAAOCAsNfPgPH8FwAAAAAAgL2z1wGmXC63ywAzZ85M3759U11dnbq6uixZsmSvznv44YfTpUuXfOxjH2uXuQAAAAAAAPbVXgeYHTt2FH77sfnz5+fyyy/PlClTsnz58owYMSKjRo1KQ0PDW57X1NSUcePG5ZOf/GSh8wAAAAAAABShVG6vrS17YciQIRk4cGBmzZrVstavX7+MHj06M2bM2ON55513Xo4//vh07tw59913X1asWLHXn9nc3Jza2to0NTWlpqbmnYwPAAAAAAB0cO3VDfZ6B0zRtmzZkmXLlmXkyJGt1keOHJmlS5fu8bzbb789zz33XK655pq9+pzNmzenubm51QsAAAAAAKA9VSzArF+/Ptu3b0/37t1brXfv3j1r167d7TnPPvtsvvGNb2TevHnp0qXLXn3OjBkzUltb2/Lq3bv3O54dAAAAAADgrVQswOxUKpVa/Vwul3dZS5Lt27fn/PPPz7Rp03LCCSfs9ftPnjw5TU1NLa81a9a845kBAAAAAADeyt5tI2kHRxxxRDp37rzLbpd169btsismSTZt2pQnnngiy5cvz1e/+tUkyY4dO1Iul9OlS5csXrw4p5566i7nVVVVpaqqqn2+BAAAAAAAwG5UbAdM165dU1dXl/r6+lbr9fX1GTZs2C7H19TU5KmnnsqKFStaXuPHj8+HPvShrFixIkOGDNlfowMAAAAAALyliu2ASZJJkyblC1/4QgYNGpShQ4fmRz/6URoaGjJ+/Pgkb94+7E9/+lPuuOOOdOrUKf379291/pFHHpnq6upd1gEAAAAAACqpogFm7Nix2bBhQ6ZPn57Gxsb0798/ixYtSp8+fZIkjY2NaWhoqOSIAAAAAAAAbVYql8vlSg+xPzU3N6e2tjZNTU2pqamp9DgAAAAAAEAFtVc3qNgzYAAAAAAAAA5UAgwAAAAAAEDBBBgAAAAAAICCCTAAAAAAAAAFE2AAAAAAAAAKJsAAAAAAAAAUTIABAAAAAAAomAADAAAAAABQMAEGAAAAAACgYAIMAAAAAABAwQQYAAAAAACAggkwAAAAAAAABRNgAAAAAAAACibAAAAAAAAAFEyAAQAAAAAAKJgAAwAAAAAAUDABBgAAAAAAoGACDAAAAAAAQMEEGAAAAAAAgIIJMAAAAAAAAAUTYAAAAAAAAAomwAAAAAAAABRMgAEAAAAAACiYAAMAAAAAAFAwAQYAAAAAAKBgAgwAAAAAAEDBBBgAAAAAAICCCTAAAAAAAAAFE2AAAAAAAAAKJsAAAAAAAAAUTIABAAAAAAAomAADAAAAAABQMAEGAAAAAACgYAIMAAAAAABAwQQYAAAAAACAggkwAAAAAAAABRNgAAAAAAAACibAAAAAAAAAFEyAAQAAAAAAKJgAAwAAAAAAUDABBgAAAAAAoGACDAAAAAAAQMEEGAAAAAAAgIIJMAAAAAAAAAUTYAAAAAAAAAomwAAAAAAAABRMgAEAAAAAACiYAAMAAAAAAFAwAQYAAAAAAKBgAgwAAAAAAEDBBBgAAAAAAICCCTAAAAAAAAAFE2AAAAAAAAAKJsAAAAAAAAAUTIABAAAAAAAomAADAAAAAABQMAEGAAAAAACgYAIMAAAAAABAwQQYAAAAAACAggkwAAAAAAAABRNgAAAAAAAACibAAAAAAAAAFEyAAQAAAAAAKJgAAwAAAAAAUDABBgAAAAAAoGACDAAAAAAAQMEqHmBmzpyZvn37prq6OnV1dVmyZMkej73nnnty2mmn5f3vf39qamoydOjQPPDAA/txWgAAAAAAgLdX0QAzf/78XH755ZkyZUqWL1+eESNGZNSoUWloaNjt8Q8++GBOO+20LFq0KMuWLcspp5ySs846K8uXL9/PkwMAAAAAAOxZqVwulyv14UOGDMnAgQMza9aslrV+/fpl9OjRmTFjxl69x0c+8pGMHTs2U6dO3avjm5ubU1tbm6amptTU1OzT3AAAAAAAwIGhvbpBxXbAbNmyJcuWLcvIkSNbrY8cOTJLly7dq/fYsWNHNm3alMMPP3yPx2zevDnNzc2tXgAAAAAAAO2pYgFm/fr12b59e7p3795qvXv37lm7du1evccNN9yQ1157LWPGjNnjMTNmzEhtbW3Lq3fv3u9obgAAAAAAgLdT0WfAJEmpVGr1c7lc3mVtd+66665861vfyvz583PkkUfu8bjJkyenqamp5bVmzZp3PDMAAAAAAMBb6VKpDz7iiCPSuXPnXXa7rFu3bpddMf/X/Pnzc/HFF2fBggX51Kc+9ZbHVlVVpaqq6h3PCwAAAAAAsLcqtgOma9euqaurS319fav1+vr6DBs2bI/n3XXXXbngggty55135swzz2zvMQEAAAAAANqsYjtgkmTSpEn5whe+kEGDBmXo0KH50Y9+lIaGhowfPz7Jm7cP+9Of/pQ77rgjyZvxZdy4cfn+97+fk08+uWX3zMEHH5za2tqKfQ8AAAAAAID/raIBZuzYsdmwYUOmT5+exsbG9O/fP4sWLUqfPn2SJI2NjWloaGg5/tZbb822bdty2WWX5bLLLmtZ/+IXv5i5c+fu7/EBAAAAAAB2q1Qul8uVHmJ/am5uTm1tbZqamlJTU1PpcQAAAAAAgApqr25QsWfAAAAAAAAAHKgEGAAAAAAAgIIJMAAAAAAAAAUTYAAAAAAAAAomwAAAAAAAABRMgAEAAAAAACiYAAMAAAAAAFAwAQYAAAAAAKBgAgwAAAAAAEDBBBgAAAAAAICCCTAAAAAAAAAFE2AAAAAAAAAKJsAAAAAAAAAUTIABAAAAAAAomAADAAAAAABQMAEGAAAAAACgYAIMAAAAAABAwQQYAAAAAACAggkwAAAAAAAABRNgAAAAAAAACibAAAAAAAAAFEyAAQAAAAAAKJgAAwAAAAAAUDABBgAAAAAAoGACDAAAAAAAQMEEGAAAAAAAgIIJMAAAAAAAAAUTYAAAAAAAAAomwAAAAAAAABRMgAEAAAAAACiYAAMAAAAAAFAwAQYAAAAAAKBgAgwAAAAAAEDBBBgAAAAAAICCCTAAAAAAAAAFE2AAAAAAAAAKJsAAAAAAAAAUTIABAAAAAAAomAADAAAAAABQMAEGAAAAAACgYAIMAAAAAABAwQQYAAAAAACAggkwAAAAAAAABRNgAAAAAAAACibAAAAAAAAAFEyAAQAAAAAAKJgAAwAAAAAAUDABBgAAAAAAoGACDAAAAAAAQMEEGAAAAAAAgIIJMAAAAAAAAAUTYAAAAAAAAAomwAAAAAAAABRMgAEAAAAAACiYAAMAAAAAAFAwAQYAAAAAAKBgAgwAAAAAAEDBBBgAAAAAAICCCTAAAAAAAAAFE2AAAAAAAAAKJsAAAAAAAAAUTIABAAAAAAAomAADAAAAAABQMAEGAAAAAACgYAIMAAAAAABAwQQYAAAAAACAglU8wMycOTN9+/ZNdXV16urqsmTJkrc8/ne/+13q6upSXV2dY489Nrfccst+mhQAAAAAAGDvVDTAzJ8/P5dffnmmTJmS5cuXZ8SIERk1alQaGhp2e/zq1atzxhlnZMSIEVm+fHmuvvrqTJgwIXffffd+nhwAAAAAAGDPSuVyuVypDx8yZEgGDhyYWbNmtaz169cvo0ePzowZM3Y5/qqrrsrChQuzatWqlrXx48fnySefzCOPPLJXn9nc3Jza2to0NTWlpqbmnX8JAAAAAACgw2qvbtClsHdqoy1btmTZsmX5xje+0Wp95MiRWbp06W7PeeSRRzJy5MhWa6effnpmz56drVu35qCDDtrlnM2bN2fz5s0tPzc1NSV58x8oAAAAAADwl21nLyh6v0rFAsz69euzffv2dO/evdV69+7ds3bt2t2es3bt2t0ev23btqxfvz49e/bc5ZwZM2Zk2rRpu6z37t37HUwPAAAAAAAcSDZs2JDa2trC3q9iAWanUqnU6udyubzL2tsdv7v1nSZPnpxJkya1/PzKK6+kT58+aWhoKPQfJEClNDc3p3fv3lmzZo1bKwIHBNc14EDjugYcaFzXgANNU1NTjj766Bx++OGFvm/FAswRRxyRzp0777LbZd26dbvsctmpR48euz2+S5cu6dat227PqaqqSlVV1S7rtbW1/g8COKDU1NS4rgEHFNc14EDjugYcaFzXgANNp06din2/Qt+tDbp27Zq6urrU19e3Wq+vr8+wYcN2e87QoUN3OX7x4sUZNGjQbp//AgAAAAAAUAkVCzBJMmnSpNx2222ZM2dOVq1alYkTJ6ahoSHjx49P8ubtw8aNG9dy/Pjx4/PCCy9k0qRJWbVqVebMmZPZs2fniiuuqNRXAAAAAAAA2EVFnwEzduzYbNiwIdOnT09jY2P69++fRYsWpU+fPkmSxsbGNDQ0tBzft2/fLFq0KBMnTswPf/jD9OrVKzfddFPOOeecvf7MqqqqXHPNNbu9LRlAR+S6BhxoXNeAA43rGnCgcV0DDjTtdV0rlXc+xR4AAAAAAIBCVPQWZAAAAAAAAAciAQYAAAAAAKBgAgwAAAAAAEDBBBgAAAAAAICCHZABZubMmenbt2+qq6tTV1eXJUuWvOXxv/vd71JXV5fq6uoce+yxueWWW/bTpAB7py3XtXvuuSennXZa3v/+96empiZDhw7NAw88sB+nBXh7bf3z2k4PP/xwunTpko997GPtOyBAG7X1urZ58+ZMmTIlffr0SVVVVT74wQ9mzpw5+2lagLfX1uvavHnzMmDAgLznPe9Jz549c+GFF2bDhg37aVqAt/bggw/mrLPOSq9evVIqlXLfffe97TlFdIMDLsDMnz8/l19+eaZMmZLly5dnxIgRGTVqVBoaGnZ7/OrVq3PGGWdkxIgRWb58ea6++upMmDAhd999936eHGD32npde/DBB3Paaadl0aJFWbZsWU455ZScddZZWb58+X6eHGD32npd26mpqSnjxo3LJz/5yf00KcDe2Zfr2pgxY/LrX/86s2fPztNPP5277rorJ5544n6cGmDP2npde+ihhzJu3LhcfPHF+cMf/pAFCxbk8ccfzyWXXLKfJwfYvddeey0DBgzIzTffvFfHF9UNSuVyubwvA79bDRkyJAMHDsysWbNa1vr165fRo0dnxowZuxx/1VVXZeHChVm1alXL2vjx4/Pkk0/mkUce2S8zA7yVtl7XducjH/lIxo4dm6lTp7bXmAB7bV+va+edd16OP/74dO7cOffdd19WrFixH6YFeHttva7df//9Oe+88/L888/n8MMP35+jAuyVtl7X/vVf/zWzZs3Kc88917L2gx/8INdff33WrFmzX2YG2FulUin33ntvRo8evcdjiuoGB9QOmC1btmTZsmUZOXJkq/WRI0dm6dKluz3nkUce2eX4008/PU888US2bt3abrMC7I19ua79Xzt27MimTZv8yz3wrrCv17Xbb789zz33XK655pr2HhGgTfblurZw4cIMGjQo119/fY466qiccMIJueKKK/LGG2/sj5EB3tK+XNeGDRuWF198MYsWLUq5XM7LL7+cX/ziFznzzDP3x8gAhSuqG3QperBKWr9+fbZv357u3bu3Wu/evXvWrl2723PWrl272+O3bduW9evXp2fPnu02L8Db2Zfr2v91ww035LXXXsuYMWPaY0SANtmX69qzzz6bb3zjG1myZEm6dDmg/vgKHAD25br2/PPP56GHHkp1dXXuvfferF+/Ppdeemk2btzoOTBAxe3LdW3YsGGZN29exo4dmz//+c/Ztm1bPv3pT+cHP/jB/hgZoHBFdYMDagfMTqVSqdXP5XJ5l7W3O3536wCV0tbr2k533XVXvvWtb2X+/Pk58sgj22s8gDbb2+va9u3bc/7552fatGk54YQT9td4AG3Wlj+v7dixI6VSKfPmzcvgwYNzxhln5MYbb8zcuXPtggHeNdpyXVu5cmUmTJiQqVOnZtmyZbn//vuzevXqjB8/fn+MCtAuiugGB9RfITziiCPSuXPnXWr8unXrdqlVO/Xo0WO3x3fp0iXdunVrt1kB9sa+XNd2mj9/fi6++OIsWLAgn/rUp9pzTIC91tbr2qZNm/LEE09k+fLl+epXv5rkzf9wWS6X06VLlyxevDinnnrqfpkdYHf25c9rPXv2zFFHHZXa2tqWtX79+qVcLufFF1/M8ccf364zA7yVfbmuzZgxI8OHD8+VV16ZJDnppJNyyCGHZMSIEbn22mvdYQbocIrqBgfUDpiuXbumrq4u9fX1rdbr6+szbNiw3Z4zdOjQXY5fvHhxBg0alIMOOqjdZgXYG/tyXUve3PlywQUX5M4773TPXeBdpa3XtZqamjz11FNZsWJFy2v8+PH50Ic+lBUrVmTIkCH7a3SA3dqXP68NHz48L730Ul599dWWtWeeeSadOnXKBz7wgXadF+Dt7Mt17fXXX0+nTq3/M2Pnzp2T/M/fGAfoSIrqBgdUgEmSSZMm5bbbbsucOXOyatWqTJw4MQ0NDS1bHidPnpxx48a1HD9+/Pi88MILmTRpUlatWpU5c+Zk9uzZueKKKyr1FQBaaet17a677sq4ceNyww035OSTT87atWuzdu3aNDU1VeorALTSlutap06d0r9//1avI488MtXV1enfv38OOeSQSn4VgCRt//Pa+eefn27duuXCCy/MypUr8+CDD+bKK6/MRRddlIMPPrhSXwOgRVuva2eddVbuueeezJo1K88//3wefvjhTJgwIYMHD06vXr0q9TUAWrz66qstf6kvSVavXp0VK1akoaEhSft1gwPqFmRJMnbs2GzYsCHTp09PY2Nj+vfvn0WLFqVPnz5JksbGxpZ/qEnSt2/fLFq0KBMnTswPf/jD9OrVKzfddFPOOeecSn0FgFbael279dZbs23btlx22WW57LLLWta/+MUvZu7cuft7fIBdtPW6BvBu19br2qGHHpr6+vp87Wtfy6BBg9KtW7eMGTMm1157baW+AkArbb2uXXDBBdm0aVNuvvnmfP3rX89hhx2WU089Ndddd12lvgJAK0888UROOeWUlp8nTZqU5H/+e1l7dYNS2T5AAAAAAACAQh1wtyADAAAAAACoNAEGAAAAAACgYAIMAAAAAABAwQQYAAAAAACAggkwAAAAAAAABRNgAAAAAAAACibAAAAAAAAAFEyAAQAAAAAAKJgAAwAAAAAAUDABBgAA6JDWrVuXL3/5yzn66KNTVVWVHj165PTTT88jjzySJCmVSrnvvvsqOyQAAPAXq0ulBwAAANgX55xzTrZu3Zqf/OQnOfbYY/Pyyy/n17/+dTZu3Fjp0QAAAOyAAQAAOp5XXnklDz30UK677rqccsop6dOnTwYPHpzJkyfnzDPPzDHHHJMk+exnP5tSqdTyc5L8+7//e+rq6lJdXZ1jjz0206ZNy7Zt21p+XyqVMmvWrIwaNSoHH3xw+vbtmwULFrT8fsuWLfnqV7+anj17prq6Osccc0xmzJixv746AADQQQgwAABAh3PooYfm0EMPzX333ZfNmzfv8vvHH388SXL77bensbGx5ecHHnggn//85zNhwoSsXLkyt956a+bOnZvvfOc7rc7/5je/mXPOOSdPPvlkPv/5z+dzn/tcVq1alSS56aabsnDhwvz85z/P008/nZ/+9KetAg8AAECSlMrlcrnSQwAAALTV3XffnS996Ut54403MnDgwHziE5/Ieeedl5NOOinJmztZ7r333owePbrlnP/3//5fRo0alcmTJ7es/fSnP80//dM/5aWXXmo5b/z48Zk1a1bLMSeffHIGDhyYmTNnZsKECfnDH/6QX/3qVymVSvvnywIAAB2OHTAAAECHdM455+Sll17KwoULc/rpp+e3v/1tBg4cmLlz5+7xnGXLlmX69OktO2gOPfTQfOlLX0pjY2Nef/31luOGDh3a6ryhQ4e27IC54IILsmLFinzoQx/KhAkTsnjx4nb5fgAAQMcmwAAAAB1WdXV1TjvttEydOjVLly7NBRdckGuuuWaPx+/YsSPTpk3LihUrWl5PPfVUnn322VRXV7/lZ+3c7TJw4MCsXr063/72t/PGG29kzJgx+fu///tCvxcAANDxCTAAAMAB48Mf/nBee+21JMlBBx2U7du3t/r9wIED8/TTT+e4447b5dWp0//869Gjjz7a6rxHH300J554YsvPNTU1GTt2bH784x9n/vz5ufvuu7Nx48Z2/GYAAEBH06XSAwAAALTVhg0bcu655+aiiy7KSSedlPe+97154okncv311+czn/lMkuSYY47Jr3/96wwfPjxVVVV53/vel6lTp+bv/u7v0rt375x77rnp1KlT/uu//itPPfVUrr322pb3X7BgQQYNGpSPf/zjmTdvXh577LHMnj07SfLd7343PXv2zMc+9rF06tQpCxYsSI8ePXLYYYdV4h8FAADwLiXAAAAAHc6hhx6aIUOG5Lvf/W6ee+65bN26Nb17986XvvSlXH311UmSG264IZMmTcqPf/zjHHXUUfnjH/+Y008/Pb/85S8zffr0XH/99TnooINy4okn5pJLLmn1/tOmTcvPfvazXHrppenRo0fmzZuXD3/4wy2ffd111+XZZ59N586d89d//ddZtGhRqx00AAAApXK5XK70EAAAAO8WpVIp9957b0aPHl3pUQAAgA7MX9ECAAAAAAAomAADAAAAAABQMM+AAQAA+F/cpRkAACiCHTAAAAAAAAAFE2AAAAAAAAAKJsAAAAAAAAAUTIABAAAAAAAomAADAAAAAABQMAEGAAAAAACgYAIMAAAAAABAwQQYAAAAAACAgv1/pCmwnstZZD4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 2000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from smdebug import modes\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = 20, 5\n",
    "\n",
    "plt.ylabel('Train Loss')\n",
    "plt.xlabel('Steps')\n",
    "plt.plot(trial.steps(mode=modes.TRAIN),\n",
    "         list(trial.tensor('CrossEntropyLoss_output_0').values(mode=modes.TRAIN).values()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
